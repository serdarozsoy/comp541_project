{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CUDA; \n",
    "using Knet\n",
    "using MLDatasets\n",
    "include(\"resnet_final.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_nll (generic function with 1 method)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss_nll(model, x, y)\n",
    "    scores = model(x)\n",
    "    loss = nll(scores, y)\n",
    "    loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validate (generic function with 1 method)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function validate(model, dtst)\n",
    "    acc = 0.0\n",
    "    batch_count = 0\n",
    "    for (x, y) in dtst\n",
    "        scores = model(x)\n",
    "        acc += accuracy(scores, y)\n",
    "        batch_count += 1\n",
    "    end\n",
    "    acc /= batch_count\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_cifar_dataset (generic function with 1 method)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_cifar_dataset()\n",
    "    xtrn,ytrn = CIFAR10.traindata(Float32);\n",
    "    ytrn = ytrn .+ 1\n",
    "    xtrn = permutedims(xtrn, (2, 1, 3, 4));\n",
    "    xtst,ytst = CIFAR10.testdata(Float32);\n",
    "    ytst = ytst .+ 1\n",
    "    xtst = permutedims(xtst, (2, 1, 3, 4));\n",
    "    xtrn, ytrn, xtst, ytst\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsize = 256\n",
    "xtrn, ytrn, xtst, ytst = load_cifar_dataset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(Any[Conv2d(P(KnetArray{Float32,4}(3,3,3,64)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(128)[1.0⋯], Knet.Ops20.relu), Sequential(Any[ResidualBlock(Sequential(Any[Conv2d(P(KnetArray{Float32,4}(3,3,64,64)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(128)[1.0⋯], Knet.Ops20.relu), Conv2d(P(KnetArray{Float32,4}(3,3,64,64)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(128)[1.0⋯], identity)]), identity), ResidualBlock(Sequential(Any[Conv2d(P(KnetArray{Float32,4}(3,3,64,64)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(128)[1.0⋯], Knet.Ops20.relu), Conv2d(P(KnetArray{Float32,4}(3,3,64,64)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(128)[1.0⋯], identity)]), identity)]), Sequential(Any[ResidualBlock(Sequential(Any[Conv2d(P(KnetArray{Float32,4}(3,3,64,128)), nothing, 1, 2, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(256)[1.0⋯], Knet.Ops20.relu), Conv2d(P(KnetArray{Float32,4}(3,3,128,128)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(256)[1.0⋯], identity)]), Sequential(Any[Conv2d(P(KnetArray{Float32,4}(1,1,64,128)), nothing, 0, 2, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(256)[1.0⋯], identity)])), ResidualBlock(Sequential(Any[Conv2d(P(KnetArray{Float32,4}(3,3,128,128)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(256)[1.0⋯], Knet.Ops20.relu), Conv2d(P(KnetArray{Float32,4}(3,3,128,128)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(256)[1.0⋯], identity)]), identity)]), Sequential(Any[ResidualBlock(Sequential(Any[Conv2d(P(KnetArray{Float32,4}(3,3,128,256)), nothing, 1, 2, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(512)[1.0⋯], Knet.Ops20.relu), Conv2d(P(KnetArray{Float32,4}(3,3,256,256)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(512)[1.0⋯], identity)]), Sequential(Any[Conv2d(P(KnetArray{Float32,4}(1,1,128,256)), nothing, 0, 2, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(512)[1.0⋯], identity)])), ResidualBlock(Sequential(Any[Conv2d(P(KnetArray{Float32,4}(3,3,256,256)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(512)[1.0⋯], Knet.Ops20.relu), Conv2d(P(KnetArray{Float32,4}(3,3,256,256)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(512)[1.0⋯], identity)]), identity)]), Sequential(Any[ResidualBlock(Sequential(Any[Conv2d(P(KnetArray{Float32,4}(3,3,256,512)), nothing, 1, 2, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(1024)[1.0⋯], Knet.Ops20.relu), Conv2d(P(KnetArray{Float32,4}(3,3,512,512)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(1024)[1.0⋯], identity)]), Sequential(Any[Conv2d(P(KnetArray{Float32,4}(1,1,256,512)), nothing, 0, 2, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(1024)[1.0⋯], identity)])), ResidualBlock(Sequential(Any[Conv2d(P(KnetArray{Float32,4}(3,3,512,512)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(1024)[1.0⋯], Knet.Ops20.relu), Conv2d(P(KnetArray{Float32,4}(3,3,512,512)), nothing, 1, 1, identity), BatchNorm2d(Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones), K32(1024)[1.0⋯], identity)]), identity)]), AvgPool2d, flatten, Linear(P(KnetArray{Float32,2}(10,512)), P(KnetArray{Float32,2}(10,1)), identity)])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(depth=18, in_ch=3, out_ch=10, cifar_stem=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in params(model)\n",
    "    p.opt = Adam(lr=0.000001)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "train_loss = zeros(epochs);\n",
    "val_acc = zeros(epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1,Train epoch loss: 5.36269866503202e-7\n",
      "Epoch: 2,Train epoch loss: 5.358686813941368e-7\n",
      "Epoch: 3,Train epoch loss: 5.31627581669734e-7\n",
      "Epoch: 4,Train epoch loss: 5.049010117848714e-7\n",
      "Epoch: 5,Train epoch loss: 5.452296672723232e-7,Accuracy: 0.8631810897435898\n",
      "Epoch: 6,Train epoch loss: 5.534444099817521e-7\n",
      "Epoch: 7,Train epoch loss: 5.608185743674253e-7\n",
      "Epoch: 8,Train epoch loss: 5.066776886964455e-7\n",
      "Epoch: 9,Train epoch loss: 5.03907601038615e-7\n",
      "Epoch: 10,Train epoch loss: 4.963806042304406e-7,Accuracy: 0.862479967948718\n",
      "Epoch: 11,Train epoch loss: 5.086263020833333e-7\n",
      "Epoch: 12,Train epoch loss: 4.961704596495017e-7\n",
      "Epoch: 13,Train epoch loss: 5.362889705560146e-7\n",
      "Epoch: 14,Train epoch loss: 4.724623301090338e-7\n",
      "Epoch: 15,Train epoch loss: 4.89885226274148e-7,Accuracy: 0.8638822115384616\n",
      "Epoch: 16,Train epoch loss: 5.264885914631379e-7\n",
      "Epoch: 17,Train epoch loss: 4.507792301667042e-7\n",
      "Epoch: 18,Train epoch loss: 4.6424758739960497e-7\n",
      "Epoch: 19,Train epoch loss: 5.035446240351751e-7\n",
      "Epoch: 20,Train epoch loss: 4.3656581487411106e-7,Accuracy: 0.864082532051282"
     ]
    }
   ],
   "source": [
    "for i in 1:epochs\n",
    "    print(\"\\nEpoch: \", i)\n",
    "    # This is done without minimize function for easier debugging\n",
    "    train_loss[i] = 0.0\n",
    "    batch_count = 0\n",
    "    dtrn = minibatch(xtrn, ytrn, bsize,shuffle=true)\n",
    "    for (x, y) in dtrn\n",
    "        loss = @diff loss_nll(model, x, y)\n",
    "        train_loss[i] += value(loss)\n",
    "        batch_count += 1\n",
    "        for p in params(model)\n",
    "            g = grad(loss, p)\n",
    "            update!(value(p), g, p.opt)\n",
    "        end\n",
    "    end\n",
    "    train_loss[i] /= batch_count\n",
    "    print(\",Train epoch loss: \", train_loss[i])\n",
    "    if mod(i, 5) == 0\n",
    "        val_batch_count = 0\n",
    "        dtst = minibatch(xtst, ytst, bsize)\n",
    "        val_acc[i] = validate(model, dtst)\n",
    "        print(\",Accuracy: \", val_acc[i])\n",
    "    end\n",
    "    #GC.gc()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1,Train epoch loss: 2.438078324000041e-6\n",
      "Epoch: 2,Train epoch loss: 2.092314072144337e-6\n",
      "Epoch: 3,Train epoch loss: 2.0559208515362862e-6\n",
      "Epoch: 4,Train epoch loss: 1.9563123201712582e-6\n",
      "Epoch: 5,Train epoch loss: 1.564927590199006e-6,Accuracy: 0.8623798076923077\n",
      "Epoch: 6,Train epoch loss: 1.4326702325772016e-6\n",
      "Epoch: 7,Train epoch loss: 1.4886451073181935e-6\n",
      "Epoch: 8,Train epoch loss: 1.2886638824756328e-6\n",
      "Epoch: 9,Train epoch loss: 1.1931818265181322e-6\n",
      "Epoch: 10,Train epoch loss: 1.0497677020537547e-6,Accuracy: 0.8625801282051282\n",
      "Epoch: 11,Train epoch loss: 1.1498729387919109e-6\n",
      "Epoch: 12,Train epoch loss: 1.1563492126953908e-6\n",
      "Epoch: 13,Train epoch loss: 9.284760707463974e-7\n",
      "Epoch: 14,Train epoch loss: 8.302239271310659e-7\n",
      "Epoch: 15,Train epoch loss: 7.54323525306506e-7,Accuracy: 0.8626802884615384\n",
      "Epoch: 16,Train epoch loss: 8.008036857996232e-7\n",
      "Epoch: 17,Train epoch loss: 7.254955096122546e-7\n",
      "Epoch: 18,Train epoch loss: 7.019975246527256e-7\n",
      "Epoch: 19,Train epoch loss: 6.402914340679462e-7\n",
      "Epoch: 20,Train epoch loss: 5.411222959176088e-7,Accuracy: 0.8626802884615384"
     ]
    }
   ],
   "source": [
    "for i in 1:epochs\n",
    "    print(\"\\nEpoch: \", i)\n",
    "    # This is done without minimize function for easier debugging\n",
    "    train_loss[i] = 0.0\n",
    "    batch_count = 0\n",
    "    dtrn = minibatch(xtrn, ytrn, bsize,shuffle=true)\n",
    "    for (x, y) in dtrn\n",
    "        loss = @diff loss_nll(model, x, y)\n",
    "        train_loss[i] += value(loss)\n",
    "        batch_count += 1\n",
    "        for p in params(model)\n",
    "            g = grad(loss, p)\n",
    "            update!(value(p), g, p.opt)\n",
    "        end\n",
    "    end\n",
    "    train_loss[i] /= batch_count\n",
    "    print(\",Train epoch loss: \", train_loss[i])\n",
    "    if mod(i, 5) == 0\n",
    "        val_batch_count = 0\n",
    "        dtst = minibatch(xtst, ytst, bsize)\n",
    "        val_acc[i] = validate(model, dtst)\n",
    "        print(\",Accuracy: \", val_acc[i])\n",
    "    end\n",
    "    #GC.gc()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1,Train epoch loss: 1.737085672525259e-5\n",
      "Epoch: 2,Train epoch loss: 1.6480340407444882e-5\n",
      "Epoch: 3,Train epoch loss: 1.4341679903177114e-5\n",
      "Epoch: 4,Train epoch loss: 1.3040464658003587e-5\n",
      "Epoch: 5,Train epoch loss: 1.1288699431297106e-5,Accuracy: 0.8613782051282052\n",
      "Epoch: 6,Train epoch loss: 1.1735562330637223e-5\n",
      "Epoch: 7,Train epoch loss: 9.927497460291937e-6\n",
      "Epoch: 8,Train epoch loss: 8.786507906057897e-6\n",
      "Epoch: 9,Train epoch loss: 8.203261173688448e-6\n",
      "Epoch: 10,Train epoch loss: 6.793840573384211e-6,Accuracy: 0.8616786858974359\n",
      "Epoch: 11,Train epoch loss: 6.289321642655593e-6\n",
      "Epoch: 12,Train epoch loss: 5.8398605921329596e-6\n",
      "Epoch: 13,Train epoch loss: 5.252028887088482e-6\n",
      "Epoch: 14,Train epoch loss: 4.77295655470628e-6\n",
      "Epoch: 15,Train epoch loss: 4.180558981039585e-6,Accuracy: 0.8621794871794872\n",
      "Epoch: 16,Train epoch loss: 4.280530489408053e-6\n",
      "Epoch: 17,Train epoch loss: 3.6356922907707017e-6\n",
      "Epoch: 18,Train epoch loss: 3.085801234612098e-6\n",
      "Epoch: 19,Train epoch loss: 2.7913122605054807e-6\n",
      "Epoch: 20,Train epoch loss: 2.852407021400256e-6,Accuracy: 0.8625801282051282"
     ]
    }
   ],
   "source": [
    "for i in 1:epochs\n",
    "    print(\"\\nEpoch: \", i)\n",
    "    # This is done without minimize function for easier debugging\n",
    "    train_loss[i] = 0.0\n",
    "    batch_count = 0\n",
    "    dtrn = minibatch(xtrn, ytrn, bsize,shuffle=true)\n",
    "    for (x, y) in dtrn\n",
    "        loss = @diff loss_nll(model, x, y)\n",
    "        train_loss[i] += value(loss)\n",
    "        batch_count += 1\n",
    "        for p in params(model)\n",
    "            g = grad(loss, p)\n",
    "            update!(value(p), g, p.opt)\n",
    "        end\n",
    "    end\n",
    "    train_loss[i] /= batch_count\n",
    "    print(\",Train epoch loss: \", train_loss[i])\n",
    "    if mod(i, 5) == 0\n",
    "        val_batch_count = 0\n",
    "        dtst = minibatch(xtst, ytst, bsize)\n",
    "        val_acc[i] = validate(model, dtst)\n",
    "        print(\",Accuracy: \", val_acc[i])\n",
    "    end\n",
    "    #GC.gc()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1,Train epoch loss: 0.006886395296225181\n",
      "Epoch: 2,Train epoch loss: 0.0009877040218084286\n",
      "Epoch: 3,Train epoch loss: 0.00042290513714154563\n",
      "Epoch: 4,Train epoch loss: 0.00030093461466141236\n",
      "Epoch: 5,Train epoch loss: 0.000208189539038218,Accuracy: 0.8595753205128205\n",
      "Epoch: 6,Train epoch loss: 0.00015340069165596594\n",
      "Epoch: 7,Train epoch loss: 0.00012459147434968216\n",
      "Epoch: 8,Train epoch loss: 0.00010527610205687009\n",
      "Epoch: 9,Train epoch loss: 8.85431774151631e-5\n",
      "Epoch: 10,Train epoch loss: 6.992263862719903e-5,Accuracy: 0.859375\n",
      "Epoch: 11,Train epoch loss: 6.169994863180014e-5\n",
      "Epoch: 12,Train epoch loss: 5.514879639332111e-5\n",
      "Epoch: 13,Train epoch loss: 4.525164572092203e-5\n",
      "Epoch: 14,Train epoch loss: 3.674099078545204e-5\n",
      "Epoch: 15,Train epoch loss: 3.593911727269491e-5,Accuracy: 0.8620793269230769\n",
      "Epoch: 16,Train epoch loss: 3.0409048000971477e-5\n",
      "Epoch: 17,Train epoch loss: 2.7837871741025877e-5\n",
      "Epoch: 18,Train epoch loss: 2.3794785524025942e-5\n",
      "Epoch: 19,Train epoch loss: 2.1704668417955057e-5\n",
      "Epoch: 20,Train epoch loss: 1.975951286462637e-5,Accuracy: 0.8616786858974359"
     ]
    }
   ],
   "source": [
    "for i in 1:epochs\n",
    "    print(\"\\nEpoch: \", i)\n",
    "    # This is done without minimize function for easier debugging\n",
    "    train_loss[i] = 0.0\n",
    "    batch_count = 0\n",
    "    dtrn = minibatch(xtrn, ytrn, bsize,shuffle=true)\n",
    "    for (x, y) in dtrn\n",
    "        loss = @diff loss_nll(model, x, y)\n",
    "        train_loss[i] += value(loss)\n",
    "        batch_count += 1\n",
    "        for p in params(model)\n",
    "            g = grad(loss, p)\n",
    "            update!(value(p), g, p.opt)\n",
    "        end\n",
    "    end\n",
    "    train_loss[i] /= batch_count\n",
    "    print(\",Train epoch loss: \", train_loss[i])\n",
    "    if mod(i, 5) == 0\n",
    "        val_batch_count = 0\n",
    "        dtst = minibatch(xtst, ytst, bsize)\n",
    "        val_acc[i] = validate(model, dtst)\n",
    "        print(\",Accuracy: \", val_acc[i])\n",
    "    end\n",
    "    #GC.gc()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1,Train epoch loss: 1.3433236635648287\n",
      "Epoch: 2,Train epoch loss: 0.7899385363627702\n",
      "Epoch: 3,Train epoch loss: 0.5810251770875393\n",
      "Epoch: 4,Train epoch loss: 0.44252078594305577\n",
      "Epoch: 5,Train epoch loss: 0.342194070877173,Accuracy: 0.7380809294871795\n",
      "Epoch: 6,Train epoch loss: 0.2610907916839306\n",
      "Epoch: 7,Train epoch loss: 0.18539956338130512\n",
      "Epoch: 8,Train epoch loss: 0.14339740971724194\n",
      "Epoch: 9,Train epoch loss: 0.11612590740506466\n",
      "Epoch: 10,Train epoch loss: 0.08744526887551332,Accuracy: 0.8005809294871795\n",
      "Epoch: 11,Train epoch loss: 0.075722463371662\n",
      "Epoch: 12,Train epoch loss: 0.06354978800966189\n",
      "Epoch: 13,Train epoch loss: 0.058929918009119155\n",
      "Epoch: 14,Train epoch loss: 0.0543970759671468\n",
      "Epoch: 15,Train epoch loss: 0.04480961330999166,Accuracy: 0.8139022435897436\n",
      "Epoch: 16,Train epoch loss: 0.039163977662340185\n",
      "Epoch: 17,Train epoch loss: 0.04437785453330248\n",
      "Epoch: 18,Train epoch loss: 0.04794140994930879\n",
      "Epoch: 19,Train epoch loss: 0.03559470335260416\n",
      "Epoch: 20,Train epoch loss: 0.033269885908334684,Accuracy: 0.8194110576923077"
     ]
    }
   ],
   "source": [
    "for i in 1:epochs\n",
    "    print(\"\\nEpoch: \", i)\n",
    "    # This is done without minimize function for easier debugging\n",
    "    train_loss[i] = 0.0\n",
    "    batch_count = 0\n",
    "    dtrn = minibatch(xtrn, ytrn, bsize,shuffle=true)\n",
    "    for (x, y) in dtrn\n",
    "        loss = @diff loss_nll(model, x, y)\n",
    "        train_loss[i] += value(loss)\n",
    "        batch_count += 1\n",
    "        for p in params(model)\n",
    "            g = grad(loss, p)\n",
    "            update!(value(p), g, p.opt)\n",
    "        end\n",
    "    end\n",
    "    train_loss[i] /= batch_count\n",
    "    print(\",Train epoch loss: \", train_loss[i])\n",
    "    if mod(i, 5) == 0\n",
    "        val_batch_count = 0\n",
    "        dtst = minibatch(xtst, ytst, bsize)\n",
    "        val_acc[i] = validate(model, dtst)\n",
    "        print(\",Accuracy: \", val_acc[i])\n",
    "    end\n",
    "    #GC.gc()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
